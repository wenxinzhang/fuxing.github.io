<!DOCTYPE HTML>
<html lang="zh-CN">

<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="福星">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="http://zhangfuxin.cn">
    <!--SEO-->

<meta name="keywords" content="Hive">


<meta name="description" content="** Hive学习之路 （二十一）Hive 优化策略：** &lt;Excerpt in index | 首页摘要&gt;
​        Hive学习之路 （二十一）Hive 优化策略

&...">


<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">
    <!--Title-->

<title>
    
    Hive学习之路 （二十一）Hive 优化策略 |
    
    福星
</title>

<link rel="alternate" href="/atom.xml" title="福星" type="application/atom+xml">


<link rel="icon" href="/favicon.ico">

    

<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.7.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">
    
<div class="hide">
    <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
    document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
    </script>
</div>




    

<script>
(function() {
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    } else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

</head></html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->
<body>
    <header class="main-header"  style="background-image:url(
    http://snippet.shenliyang.com/img/banner.jpg)"
     >
    <div class="main-header-box">
        <a class="header-avatar" href="/" title='福 星'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
            <!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
            <img src="/img/branding.png" alt="Snippet 博客主题" class="img-responsive center-block">
            
        </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                        <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://zhangfuxin.cn">
                        福星</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                        <li role="presentation" class="text-center">
                            <a href="/"><i class="fa "></i>
                                首页</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/categories/Linux/"><i class="fa "></i>
                                Linux</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/categories/Hadoop/"><i class="fa "></i>
                                Hadoop</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/categories/Spark/"><i class="fa "></i>
                                Spark</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/categories/Java/"><i class="fa "></i>
                                Java</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/categories/Python/"><i class="fa "></i>
                                Python</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/categories/algorithm/"><i class="fa "></i>
                                算法</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/categories/工具/"><i class="fa "></i>
                                工具</a>
                        </li>
                        
                        <li role="presentation" class="text-center">
                            <a href="/archives/"><i class="fa "></i>
                                时间轴</a>
                        </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="Hive学习之路 （二十一）Hive 优化策略">
            
            Hive学习之路 （二十一）Hive 优化策略
            
        </h1>
        <div class="post-meta">
    
    <span class="categories-meta fa-wrap">
        <i class="fa fa-folder-open-o"></i>
        <a class="category-link" href="/categories/Hadoop/">Hadoop</a>
    </span>
    
    
    <span class="fa-wrap">
        <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
            <a class="tag-link" href="/tags/Hive/">Hive</a>
            
        </span>
    </span>
    
    
    
    <span class="fa-wrap">
        <i class="fa fa-clock-o"></i>
        <span class="date-meta">
            2019/04/21</span>
    </span>
    
    <span class="fa-wrap">
        <i class="fa fa-eye"></i>
        <span id="busuanzi_value_page_pv"></span>
    </span>
    
    
</div>
        
        
    </div>
    
    <div class="post-body post-content">
        <p>** Hive学习之路 （二十一）Hive 优化策略：** &lt;Excerpt in index | 首页摘要&gt;</p>
<p>​        Hive学习之路 （二十一）Hive 优化策略</p>
<a id="more"></a>
<p>&lt;The rest of contents | 余下全文&gt;</p>
<h2 id="一、Hadoop-框架计算特性"><a href="#一、Hadoop-框架计算特性" class="headerlink" title="一、Hadoop 框架计算特性"></a>一、Hadoop 框架计算特性</h2><p>1、数据量大不是问题，数据倾斜是个问题</p>
<p>2、jobs 数比较多的作业运行效率相对比较低，比如即使有几百行的表，如果多次关联多次 汇总，产生十几个 jobs，耗时很长。原因是 map reduce 作业初始化的时间是比较长的</p>
<p>3、sum,count,max,min 等 UDAF，不怕数据倾斜问题，hadoop 在 map 端的汇总合并优化，使 数据倾斜不成问题</p>
<p>4、count(distinct userid)，在数据量大的情况下，效率较低，如果是多 count(distinct userid,month)效率更低，因为 count(distinct)是按 group by 字段分组，按 distinct 字段排序， 一般这种分布方式是很</p>
<p>倾斜的，比如 PV 数据，淘宝一天 30 亿的 pv，如果按性别分组，分 配 2 个 reduce，每个 reduce 期望处理 15 亿数据，但现实必定是男少女多</p>
<h2 id="二、优化常用手段"><a href="#二、优化常用手段" class="headerlink" title="二、优化常用手段"></a>二、优化常用手段</h2><p>1、好的模型设计事半功倍</p>
<p>2、解决数据倾斜问题</p>
<p>3、减少 job 数</p>
<p>4、设置合理的 MapReduce 的 task 数，能有效提升性能。(比如，10w+级别的计算，用 160个 reduce，那是相当的浪费，1 个足够)</p>
<p>5、了解数据分布，自己动手解决数据倾斜问题是个不错的选择。这是通用的算法优化，但 算法优化有时不能适应特定业务背景，开发人员了解业务，了解数据，可以通过业务逻辑精 确有效的解决数据倾斜问题</p>
<p>6、数据量较大的情况下，慎用 count(distinct)，group by 容易产生倾斜问题</p>
<p>7、对小文件进行合并，是行之有效的提高调度效率的方法，假如所有的作业设置合理的文 件数，对云梯的整体调度效率也会产生积极的正向影响</p>
<p>8、优化时把握整体，单个作业最优不如整体最优</p>
<h2 id="三、排序选择"><a href="#三、排序选择" class="headerlink" title="三、排序选择"></a>三、排序选择</h2><p><strong>cluster by</strong>：对同一字段分桶并排序，不能和 sort by 连用</p>
<p><strong>distribute by + sort by</strong>：分桶，保证同一字段值只存在一个结果文件当中，结合 sort by 保证 每个 reduceTask 结果有序</p>
<p><strong>sort by</strong>：单机排序，单个 reduce 结果有序</p>
<p><strong>order by</strong>：全局排序，缺陷是只能使用一个 reduce</p>
<p><strong>一定要区分这四种排序的使用方式和适用场景</strong></p>
<h2 id="四、怎样做笛卡尔积"><a href="#四、怎样做笛卡尔积" class="headerlink" title="四、怎样做笛卡尔积"></a>四、怎样做笛卡尔积</h2><p>当 Hive 设定为严格模式（hive.mapred.mode=strict）时，不允许在 HQL 语句中出现笛卡尔积， 这实际说明了 Hive 对笛卡尔积支持较弱。因为找不到 Join key，Hive 只能使用 1 个 reducer 来完成笛卡尔积。</p>
<p>当然也可以使用 limit 的办法来减少某个表参与 join 的数据量，但对于需要笛卡尔积语义的 需求来说，经常是一个大表和一个小表的 Join 操作，结果仍然很大（以至于无法用单机处 理），这时 MapJoin才是最好的解决办法。MapJoin，顾名思义，会在 Map 端完成 Join 操作。 这需要将 Join 操作的一个或多个表完全读入内存。</p>
<p>PS：MapJoin 在子查询中可能出现未知 BUG。在大表和小表做笛卡尔积时，规避笛卡尔积的 方法是，给 Join 添加一个 Join key，<strong>原理很简单：将小表扩充一列 join key，并将小表的条 目复制数倍，join</strong> <strong>key 各不相同；将大表扩充一列 join key 为随机数。</strong></p>
<p><strong>精髓就在于复制几倍，最后就有几个 reduce 来做，而且大表的数据是前面小表扩张 key 值 范围里面随机出来的，所以复制了几倍 n，就相当于这个随机范围就有多大 n，那么相应的， 大表的数据就被随机的分为了 n 份。并且最后处理所用的 reduce 数量也是 n，而且也不会 出现数据倾斜。</strong></p>
<h2 id="五、怎样写-in-exists-语句"><a href="#五、怎样写-in-exists-语句" class="headerlink" title="五、怎样写 in/exists 语句"></a>五、怎样写 in/exists 语句</h2><p>虽然经过测验，hive1.2.1 也支持 in/exists 操作，但还是推荐使用 hive 的一个高效替代方案：<strong>left semi join</strong></p>
<p>比如说：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">where</span> a.id <span class="keyword">in</span> (<span class="keyword">select</span> b.id <span class="keyword">from</span> b);</span><br><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">where</span> <span class="keyword">exists</span> (<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> b <span class="keyword">where</span> a.id = b.id);</span><br></pre></td></tr></table></figure>

<p>应该转换成：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> a.id, a.name <span class="keyword">from</span> a <span class="keyword">left</span> <span class="keyword">semi</span> <span class="keyword">join</span> b <span class="keyword">on</span> a.id = b.id;</span><br></pre></td></tr></table></figure>

<h2 id="六、设置合理的-maptask-数量"><a href="#六、设置合理的-maptask-数量" class="headerlink" title="六、设置合理的 maptask 数量"></a>六、设置合理的 maptask 数量</h2><p>Map 数过大</p>
<p>　　Map 阶段输出文件太小，产生大量小文件</p>
<p>　　初始化和创建 Map 的开销很大</p>
<p>Map 数太小</p>
<p>　　文件处理或查询并发度小，Job 执行时间过长</p>
<p>　　大量作业时，容易堵塞集群 </p>
<p>在 MapReduce 的编程案例中，我们得知，一个MR Job的 MapTask 数量是由输入分片 InputSplit 决定的。而输入分片是由 FileInputFormat.getSplit()决定的。一个输入分片对应一个 MapTask， 而输入分片是由三个参数决定的：</p>
<p><img src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180415151017302-1064661736.png" alt="img"></p>
<p>输入分片大小的计算是这么计算出来的：</p>
<p><strong>long splitSize = Math.max(minSize, Math.min(maxSize, blockSize))</strong></p>
<p>默认情况下，输入分片大小和 HDFS 集群默认数据块大小一致，也就是默认一个数据块，启 用一个 MapTask 进行处理，这样做的好处是避免了服务器节点之间的数据传输，提高 job 处 理效率</p>
<p>两种经典的控制 MapTask 的个数方案：减少 MapTask 数或者增加 MapTask 数</p>
<blockquote>
<p><strong>1、 减少 MapTask 数是通过合并小文件来实现，这一点主要是针对数据源</strong></p>
<p><strong>2、 增加 MapTask 数可以通过控制上一个 job 的 reduceTask 个数</strong> </p>
</blockquote>
<p>因为 Hive 语句最终要转换为一系列的 MapReduce Job 的，而每一个 MapReduce Job 是由一 系列的 MapTask 和 ReduceTask 组成的，默认情况下， MapReduce 中一个 MapTask 或者一个 ReduceTask 就会启动一个 JVM 进程，一个 Task 执行完毕后， JVM 进程就退出。这样如果任 务花费时间很短，又要多次启动 JVM 的情况下，JVM 的启动时间会变成一个比较大的消耗， 这个时候，就可以通过重用 JVM 来解决：</p>
<blockquote>
<p> <strong>set mapred.job.reuse.jvm.num.tasks=5</strong> </p>
</blockquote>
<h2 id="七、小文件合并"><a href="#七、小文件合并" class="headerlink" title="七、小文件合并"></a>七、小文件合并</h2><p>文件数目过多，会给 HDFS 带来压力，并且会影响处理效率，可以通过合并 Map 和 Reduce 的 结果文件来消除这样的影响：</p>
<blockquote>
<p><strong>set hive.merge.mapfiles = true ##在 map only 的任务结束时合并小文件</strong></p>
<p><strong>set hive.merge.mapredfiles = false ## true 时在 MapReduce 的任务结束时合并小文件</strong></p>
<p><strong>set hive.merge.size.per.task = 256*1000*1000 ##合并文件的大小</strong></p>
<p><strong>set mapred.max.split.size=256000000; ##每个 Map 最大分割大小</strong></p>
<p><strong>set mapred.min.split.size.per.node=1; ##一个节点上 split 的最少值</strong></p>
<p><strong>set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; ##执行 Map 前进行小文件合并</strong></p>
</blockquote>
<h2 id="八、设置合理的-reduceTask-的数量"><a href="#八、设置合理的-reduceTask-的数量" class="headerlink" title="八、设置合理的 reduceTask 的数量"></a>八、设置合理的 reduceTask 的数量</h2><p>Hadoop MapReduce 程序中，reducer 个数的设定极大影响执行效率，这使得 Hive 怎样决定 reducer 个数成为一个关键问题。遗憾的是 Hive 的估计机制很弱，不指定 reducer 个数的情 况下，Hive 会猜测确定一个 reducer 个数，基于以下两个设定：</p>
<blockquote>
<p>1、hive.exec.reducers.bytes.per.reducer（默认为 256000000）</p>
<p>2、hive.exec.reducers.max（默认为 1009）</p>
<p>3、mapreduce.job.reduces=-1（设置一个常量 reducetask 数量）</p>
</blockquote>
<p>计算 reducer 数的公式很简单： N=min(参数 2，总输入数据量/参数 1) 通常情况下，有必要手动指定 reducer 个数。考虑到 map 阶段的输出数据量通常会比输入有 大幅减少，因此即使不设定 reducer 个数，重设参数 2 还是必要的。</p>
<p><strong>依据 Hadoop 的经验，可以将参数 2 设定为 0.95*(集群中 datanode 个数)。</strong> </p>
<h2 id="九、合并-MapReduce-操作"><a href="#九、合并-MapReduce-操作" class="headerlink" title="九、合并 MapReduce 操作"></a>九、合并 MapReduce 操作</h2><p>Multi-group by 是 Hive 的一个非常好的特性，它使得 Hive 中利用中间结果变得非常方便。 例如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FROM (<span class="keyword">SELECT</span> a.status, b.school, b.gender <span class="keyword">FROM</span> status_updates a <span class="keyword">JOIN</span> <span class="keyword">profiles</span> b <span class="keyword">ON</span> (a.userid =</span><br><span class="line">b.userid <span class="keyword">and</span> a.ds=<span class="string">'2009-03-20'</span> ) ) subq1</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> gender_summary <span class="keyword">PARTITION</span>(ds=<span class="string">'2009-03-20'</span>)</span><br><span class="line"><span class="keyword">SELECT</span> subq1.gender, <span class="keyword">COUNT</span>(<span class="number">1</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> subq1.gender</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> school_summary <span class="keyword">PARTITION</span>(ds=<span class="string">'2009-03-20'</span>)</span><br><span class="line"><span class="keyword">SELECT</span> subq1.school, <span class="keyword">COUNT</span>(<span class="number">1</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> subq1.school</span><br></pre></td></tr></table></figure>

<p>上述查询语句使用了 multi-group by 特性连续 group by 了 2 次数据，使用不同的 group by key。 这一特性可以减少一次 MapReduce 操作</p>
<h2 id="十、合理利用分桶：Bucketing-和-Sampling"><a href="#十、合理利用分桶：Bucketing-和-Sampling" class="headerlink" title="十、合理利用分桶：Bucketing 和 Sampling"></a>十、合理利用分桶：Bucketing 和 Sampling</h2><p>Bucket 是指将数据以指定列的值为 key 进行 hash，hash 到指定数目的桶中。这样就可以支 持高效采样了。如下例就是以 userid 这一列为 bucket 的依据，共设置 32 个 buckets</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="built_in">INT</span>, userid <span class="built_in">BIGINT</span>,</span><br><span class="line"> page_url <span class="keyword">STRING</span>, referrer_url <span class="keyword">STRING</span>,</span><br><span class="line"> ip <span class="keyword">STRING</span> <span class="keyword">COMMENT</span> <span class="string">'IP Address of the User'</span>)</span><br><span class="line"> <span class="keyword">COMMENT</span> <span class="string">'This is the page view table'</span></span><br><span class="line"> PARTITIONED <span class="keyword">BY</span>(dt <span class="keyword">STRING</span>, country <span class="keyword">STRING</span>)</span><br><span class="line"> CLUSTERED <span class="keyword">BY</span>(userid) SORTED <span class="keyword">BY</span>(viewTime) <span class="keyword">INTO</span> <span class="number">32</span> BUCKETS</span><br><span class="line"> <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></span><br><span class="line"> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'1'</span></span><br><span class="line"> COLLECTION ITEMS <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'2'</span></span><br><span class="line"> <span class="keyword">MAP</span> <span class="keyword">KEYS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'3'</span></span><br><span class="line"> <span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure>

<p>通常情况下，Sampling 在全体数据上进行采样，这样效率自然就低，它要去访问所有数据。 而如果一个表已经对某一列制作了 bucket，就可以采样所有桶中指定序号的某个桶，这就 减少了访问量。</p>
<p>如下例所示就是采样了 page_view 中 32 个桶中的第三个桶的全部数据：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> page_view <span class="keyword">TABLESAMPLE</span>(<span class="keyword">BUCKET</span> <span class="number">3</span> <span class="keyword">OUT</span> <span class="keyword">OF</span> <span class="number">32</span>);</span><br></pre></td></tr></table></figure>

<p>如下例所示就是采样了 page_view 中 32 个桶中的第三个桶的一半数据：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> page_view <span class="keyword">TABLESAMPLE</span>(<span class="keyword">BUCKET</span> <span class="number">3</span> <span class="keyword">OUT</span> <span class="keyword">OF</span> <span class="number">64</span>);</span><br></pre></td></tr></table></figure>

<h2 id="十一、合理利用分区：Partition"><a href="#十一、合理利用分区：Partition" class="headerlink" title="十一、合理利用分区：Partition"></a>十一、合理利用分区：Partition</h2><p> Partition 就是分区。分区通过在创建表时启用 partitioned by 实现，用来 partition 的维度并不 是实际数据的某一列，具体分区的标志是由插入内容时给定的。当要查询某一分区的内容时 可以采用 where 语句，形似 where tablename.partition_column = a 来实现。</p>
<p>创建含分区的表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="built_in">INT</span>, userid <span class="built_in">BIGINT</span>,</span><br><span class="line"> page_url <span class="keyword">STRING</span>, referrer_url <span class="keyword">STRING</span>,</span><br><span class="line"> ip <span class="keyword">STRING</span> <span class="keyword">COMMENT</span> <span class="string">'IP Address of the User'</span>)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(<span class="built_in">date</span> <span class="keyword">STRING</span>, country <span class="keyword">STRING</span>)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'1'</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE;</span><br></pre></td></tr></table></figure>

<p>载入内容，并指定分区标志</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/hadoop/pv_2008-06-08_us.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> page_view</span><br><span class="line"><span class="keyword">partition</span>(<span class="built_in">date</span>=<span class="string">'2008-06-08'</span>, country=<span class="string">'US'</span>);</span><br></pre></td></tr></table></figure>

<p>查询指定标志的分区内容</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> page_views.* <span class="keyword">FROM</span> page_views</span><br><span class="line"> <span class="keyword">WHERE</span> page_views.date &gt;= <span class="string">'2008-03-01'</span> <span class="keyword">AND</span> page_views.date &lt;= <span class="string">'2008-03-31'</span> <span class="keyword">AND</span></span><br><span class="line">page_views.referrer_url <span class="keyword">like</span> <span class="string">'%xyz.com'</span>;</span><br></pre></td></tr></table></figure>

<h2 id="十二、Join-优化"><a href="#十二、Join-优化" class="headerlink" title="十二、Join 优化"></a>十二、Join 优化</h2><p>总体原则：</p>
<p>　　1、 优先过滤后再进行 Join 操作，最大限度的减少参与 join 的数据量</p>
<p>　　2、 小表 join 大表，最好启动 mapjoin</p>
<p>　　3、 Join on 的条件相同的话，最好放入同一个 job，并且 join 表的排列顺序从小到大 </p>
<p><strong>在使用写有 Join 操作的查询语句时有一条原则：应该将条目少的表/子查询放在 Join 操作 符的左边。</strong>原因是在 Join 操作的 Reduce 阶段，位于 Join 操作符左边的表的内容会被加 载进内存，将条目少的表放在左边，可以有效减少发生 OOM 错误的几率。对于一条语句 中有多个 Join 的情况，如果 Join 的条件相同，比如查询</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_users</span><br><span class="line"><span class="keyword">SELECT</span> pv.pageid, u.age <span class="keyword">FROM</span> page_view p</span><br><span class="line"><span class="keyword">JOIN</span> <span class="keyword">user</span> u <span class="keyword">ON</span> (pv.userid = u.userid)</span><br><span class="line"><span class="keyword">JOIN</span> newuser x <span class="keyword">ON</span> (u.userid = x.userid);</span><br></pre></td></tr></table></figure>

<p>如果 Join 的 key 相同，不管有多少个表，都会则会合并为一个 Map-Reduce 任务，而不 是”n”个，在做 OUTER JOIN 的时候也是一样</p>
<p>如果 join 的条件不相同，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">INSERT OVERWRITE TABLE pv_users</span><br><span class="line"> SELECT pv.pageid, u.age FROM page_view p</span><br><span class="line"> JOIN user u ON (pv.userid = u.userid)</span><br><span class="line"> JOIN newuser x on (u.age = x.age);</span><br></pre></td></tr></table></figure>

<p>Map-Reduce 的任务数目和 Join 操作的数目是对应的，上述查询和以下查询是等价的</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--先 page_view 表和 user 表做链接</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tmptable</span><br><span class="line"> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> page_view p <span class="keyword">JOIN</span> <span class="keyword">user</span> u <span class="keyword">ON</span> (pv.userid = u.userid);</span><br><span class="line"><span class="comment">-- 然后结果表 temptable 和 newuser 表做链接</span></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> pv_users</span><br><span class="line"> <span class="keyword">SELECT</span> x.pageid, x.age <span class="keyword">FROM</span> tmptable x <span class="keyword">JOIN</span> newuser y <span class="keyword">ON</span> (x.age = y.age);</span><br></pre></td></tr></table></figure>

<p>在编写 Join 查询语句时，如果确定是由于 join 出现的数据倾斜，那么请做如下设置：</p>
<blockquote>
<p><strong>set hive.skewjoin.key=100000; // 这个是 join 的键对应的记录条数超过这个值则会进行 分拆，值根据具体数据量设置</strong></p>
<p><strong>set hive.optimize.skewjoin=true; // 如果是 join 过程出现倾斜应该设置为 true</strong> </p>
</blockquote>
<h2 id="十三、Group-By-优化"><a href="#十三、Group-By-优化" class="headerlink" title="十三、Group By 优化"></a>十三、Group By 优化</h2><h3 id="1、Map-端部分聚合"><a href="#1、Map-端部分聚合" class="headerlink" title="1、Map 端部分聚合"></a>1、Map 端部分聚合</h3><p>并不是所有的聚合操作都需要在 Reduce 端完成，很多聚合操作都可以先在 Map 端进 行部分聚合，最后在 Reduce 端得出最终结果。</p>
<p>MapReduce 的 combiner 组件参数包括：</p>
<blockquote>
<p><strong>set hive.map.aggr = true 是否在 Map 端进行聚合，默认为 True</strong></p>
<p><strong>set hive.groupby.mapaggr.checkinterval = 100000 在 Map 端进行聚合操作的条目数目</strong></p>
</blockquote>
<h3 id="2、使用-Group-By-有数据倾斜的时候进行负载均衡"><a href="#2、使用-Group-By-有数据倾斜的时候进行负载均衡" class="headerlink" title="2、使用 Group By 有数据倾斜的时候进行负载均衡"></a>2、使用 Group By 有数据倾斜的时候进行负载均衡</h3><blockquote>
<p> <strong>set hive.groupby.skewindata = true</strong></p>
</blockquote>
<p>当 sql 语句使用 groupby 时数据出现倾斜时，如果该变量设置为 true，那么 Hive 会自动进行 负载均衡。<strong>策略就是把 MR 任务拆分成两个：第一个先做预汇总，第二个再做最终汇总</strong></p>
<p>在 MR 的第一个阶段中，Map 的输出结果集合会缓存到 maptaks 中，每个 Reduce 做部分聚 合操作，并输出结果，这样处理的结果是相同 Group By Key 有可能被分发到不同的 Reduce 中， 从而达到负载均衡的目的；第二个阶段 再根据预处理的数据结果按照 Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成 最终的聚合操作。</p>
<h2 id="十四、合理利用文件存储格式"><a href="#十四、合理利用文件存储格式" class="headerlink" title="十四、合理利用文件存储格式"></a>十四、合理利用文件存储格式</h2><p>创建表时，尽量使用 orc、parquet 这些列式存储格式，因为列式存储的表，每一列的数据在 物理上是存储在一起的，Hive 查询时会只遍历需要列数据，大大减少处理的数据量。</p>
<h2 id="十五、本地模式执行-MapReduce"><a href="#十五、本地模式执行-MapReduce" class="headerlink" title="十五、本地模式执行 MapReduce"></a>十五、本地模式执行 MapReduce</h2><p>Hive 在集群上查询时，默认是在集群上 N 台机器上运行， 需要多个机器进行协调运行，这 个方式很好地解决了大数据量的查询问题。但是当 Hive 查询处理的数据量比较小时，其实 没有必要启动分布式模式去执行，因为以分布式方式执行就涉及到跨网络传输、多节点协调 等，并且消耗资源。这个时间可以只使用本地模式来执行 mapreduce job，只在一台机器上 执行，速度会很快。启动本地模式涉及到三个参数：</p>
<p><img src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180415152400015-1874477482.png" alt="img"></p>
<p>set hive.exec.mode.local.auto=true 是打开 hive 自动判断是否启动本地模式的开关，但是只 是打开这个参数并不能保证启动本地模式，要当 map 任务数不超过</p>
<p>hive.exec.mode.local.auto.input.files.max 的个数并且 map 输入文件大小不超过</p>
<p>hive.exec.mode.local.auto.inputbytes.max 所指定的大小时，才能启动本地模式。</p>
<h2 id="十六、并行化处理"><a href="#十六、并行化处理" class="headerlink" title="十六、并行化处理"></a>十六、并行化处理</h2><p>一个 hive sql 语句可能会转为多个 mapreduce Job，每一个 job 就是一个 stage，这些 job 顺序 执行，这个在 cli 的运行日志中也可以看到。但是有时候这些任务之间并不是是相互依赖的， 如果集群资源允许的话，可以让多个并不相互依赖 stage 并发执行，这样就节约了时间，提 高了执行速度，但是如果集群资源匮乏时，启用并行化反倒是会导致各个 job 相互抢占资源 而导致整体执行性能的下降。启用并行化：</p>
<blockquote>
<p><strong>set hive.exec.parallel=true;</strong></p>
<p><strong>set hive.exec.parallel.thread.number=8; //同一个 sql 允许并行任务的最大线程数</strong></p>
</blockquote>
<h2 id="十七、设置压缩存储"><a href="#十七、设置压缩存储" class="headerlink" title="十七、设置压缩存储"></a>十七、设置压缩存储</h2><h3 id="1、压缩的原因"><a href="#1、压缩的原因" class="headerlink" title="1、压缩的原因"></a>1、压缩的原因</h3><p>Hive 最终是转为 MapReduce 程序来执行的，而 MapReduce 的性能瓶颈在于网络 IO 和 磁盘 IO，要解决性能瓶颈，最主要的是减少数据量，对数据进行压缩是个好的方式。压缩 虽然是减少了数据量，但是压缩过程要消耗 CPU 的，但是在 Hadoop 中， 往往性能瓶颈不 在于 CPU，CPU 压力并不大，所以压缩充分利用了比较空闲的 CPU</p>
<h3 id="2、常用压缩方法对比"><a href="#2、常用压缩方法对比" class="headerlink" title="2、常用压缩方法对比"></a>2、常用压缩方法对比</h3><p><img src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180415152559984-1857141726.png" alt="img"></p>
<p>各个压缩方式所对应的 Class 类：</p>
<p><img src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180415152617806-1546480457.png" alt="img"></p>
<h3 id="3、压缩方式的选择"><a href="#3、压缩方式的选择" class="headerlink" title="3、压缩方式的选择"></a>3、压缩方式的选择</h3><blockquote>
<p><strong>压缩比率</strong></p>
<p><strong>压缩解压缩速度</strong></p>
<p><strong>是否支持 Split</strong></p>
</blockquote>
<h3 id="4、压缩使用"><a href="#4、压缩使用" class="headerlink" title="4、压缩使用"></a>4、压缩使用</h3><p>Job 输出文件按照 block 以 GZip 的方式进行压缩：</p>
<blockquote>
<p><strong>set mapreduce.output.fileoutputformat.compress=true // 默认值是 false</strong></p>
<p><strong>set mapreduce.output.fileoutputformat.compress.type=BLOCK // 默认值是 Record</strong></p>
<p><strong>set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec // 默认值是 org.apache.hadoop.io.compress.DefaultCodec</strong></p>
</blockquote>
<p>Map 输出结果也以 Gzip 进行压缩：</p>
<blockquote>
<p><strong>set mapred.map.output.compress=true</strong></p>
<p><strong>set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.GzipCodec // 默认值是 org.apache.hadoop.io.compress.DefaultCodec</strong> </p>
</blockquote>
<p>对 Hive 输出结果和中间都进行压缩：</p>
<blockquote>
<p><strong>set hive.exec.compress.output=true // 默认值是 false，不压缩</strong></p>
<p><strong>set hive.exec.compress.intermediate=true // 默认值是 false，为 true 时 MR 设置的压缩才启用</strong></p>
</blockquote>

    </div>
    
    <div class="post-footer">
        <div>
            
            转载声明：
            商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="https://github.com/wenxinzhang" target="_blank">福星</a>
            
            
        </div>
        <div>
            
        </div>
    </div>
</article>
<div class="article-nav prev-next-wrap clearfix">
    
    <a href="/2019-05-01-Scala学习之路 （一）Scala的安装.html" class="pre-post btn btn-default" title='Scala学习之路 （一）Scala的安装'>
        <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
        <span class="hidden-xs">
            Scala学习之路 （一）Scala的安装</span>
    </a>
    
    
    <a href="/2019-04-20-Hive学习之路 （二十）Hive 执行过程实例分析.html" class="next-post btn btn-default" title='Hive学习之路 （二十）Hive 执行过程实例分析'>
        <span class="hidden-lg">下一篇</span>
        <span class="hidden-xs">
            Hive学习之路 （二十）Hive 执行过程实例分析</span><i class="fa fa-angle-right fa-fw"></i>
    </a>
    
</div>

<div id="comments">
    

<div id="vcomments" class="valine"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>
<script>
new Valine({
    av: AV,
    el: '#vcomments',
    appId: 'UckE9LEIQ8aoa3MH1Kio27rB-gzGzoHsz',
    appKey: '7HC9xCVYQdshKqFRDmULFm5G',
    placeholder: '说点什么吧',
    notify: false,
    verify: true,
    avatar: 'mm',
    meta: 'nick,mail'.split(','),
    pageSize: '10',
    path: window.location.pathname,
    lang: 'zh-CN'.toLowerCase()
})
</script>


</div>

                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">
            文章目录
        </h3>
        
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、Hadoop-框架计算特性"><span class="toc-text">一、Hadoop 框架计算特性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、优化常用手段"><span class="toc-text">二、优化常用手段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、排序选择"><span class="toc-text">三、排序选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#四、怎样做笛卡尔积"><span class="toc-text">四、怎样做笛卡尔积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#五、怎样写-in-exists-语句"><span class="toc-text">五、怎样写 in/exists 语句</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#六、设置合理的-maptask-数量"><span class="toc-text">六、设置合理的 maptask 数量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#七、小文件合并"><span class="toc-text">七、小文件合并</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#八、设置合理的-reduceTask-的数量"><span class="toc-text">八、设置合理的 reduceTask 的数量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#九、合并-MapReduce-操作"><span class="toc-text">九、合并 MapReduce 操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#十、合理利用分桶：Bucketing-和-Sampling"><span class="toc-text">十、合理利用分桶：Bucketing 和 Sampling</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#十一、合理利用分区：Partition"><span class="toc-text">十一、合理利用分区：Partition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#十二、Join-优化"><span class="toc-text">十二、Join 优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#十三、Group-By-优化"><span class="toc-text">十三、Group By 优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、Map-端部分聚合"><span class="toc-text">1、Map 端部分聚合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、使用-Group-By-有数据倾斜的时候进行负载均衡"><span class="toc-text">2、使用 Group By 有数据倾斜的时候进行负载均衡</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#十四、合理利用文件存储格式"><span class="toc-text">十四、合理利用文件存储格式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#十五、本地模式执行-MapReduce"><span class="toc-text">十五、本地模式执行 MapReduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#十六、并行化处理"><span class="toc-text">十六、并行化处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#十七、设置压缩存储"><span class="toc-text">十七、设置压缩存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、压缩的原因"><span class="toc-text">1、压缩的原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、常用压缩方法对比"><span class="toc-text">2、常用压缩方法对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3、压缩方式的选择"><span class="toc-text">3、压缩方式的选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4、压缩使用"><span class="toc-text">4、压缩使用</span></a></li></ol></li></ol>
        
    </div>
</aside>
                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>
<a id="back-to-top" class="icon-btn hide">
    <i class="fa fa-chevron-up"></i>
</a>
    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
    访问量:
    <strong id="busuanzi_value_site_pv">
        <i class="fa fa-spinner fa-spin"></i>
    </strong>
    &nbsp; | &nbsp;
    访客数:
    <strong id="busuanzi_value_site_uv">
        <i class="fa fa-spinner fa-spin"></i>
    </strong>
    
</div>
            </div>
            <div class="col-sm-12">
                <span>Copyright &copy;
                    2018
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>



<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<script src="/js/app.js?rev=@@hash"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"right","width":200,"height":350},"mobile":{"show":true}});</script></body>
</html>